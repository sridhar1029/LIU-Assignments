mu = mu_new
}
for(it in 1:max_it) {
plot(mu[1,], type="o", col="blue", ylim=c(0,1))
points(mu[2,], type="o", col="red")
points(mu[3,], type="o", col="green")
#points(mu[4,], type="o", col="yellow")
Sys.sleep(0.5)
# E-step: Computation of the fractional component assignments
# Your code here
pi_temp <- vector(length = K)
mu_temp <- matrix(nrow=K, ncol=D)
total_pi = matrix(0, nrow = N, ncol = D)
for(i in 1:K){
total_pi = total_pi + (pi[i]*dbinom(x,1,mu[i,]))
}
for(i in 1:K){
ith_estep <- (pi[i]*dbinom(x,1,mu[i, ])) / total_pi
# estimate pi
pi_temp[i] <- mean(ith_estep)
# estimate p,q
mu_temp[i,] <- colSums(x*ith_estep) / colSums(ith_estep)
}
pi_new = pi_temp
mu_new = mu_temp
#Log likelihood computation.
# Your code here
if(it%%2==0){
print(pi_new)
print(mu_new)
}
cat("iteration: ", it, "log likelihood: ", llik[it], "\n")
flush.console()
# Stop if the lok likelihood has not changed significantly
# Your code here
#M-step: ML parameter estimation from the data and fractional component assignments
# Your code here
pi = pi_new
mu = mu_new
}
a
b
colSums(a)/colSums(b)
b[1,]/a[1,]
a = c(1, 0,1,,0,0,0,0,0,1)
a = c(1, 0,1,1,0,0,0,0,0,1)
a
?dbnorm
?dbinom
dbinom(x,1,mu[i, ])
pi
## Expectation Step
estep <- function(obs, pi, cur){
pi_estep = matrix(nrow = 3, ncol = length(obs))
tot = ( pi[1]*dbinom(obs,1,cur[1]) + pi[2]*dbinom(obs,1,cur[2]) + pi[3]*dbinom(obs,1,cur[3]) )
for( i in 1:3){
pi_estep[i,] <- (pi[i]*dbinom(obs,1,cur[i])) / tot
}
#print(dim(pi_estep))
return(pi_estep)
}
## Maximization Step
mstep <- function(obs,e.step){
# estimate pi
pi_temp <- rowMeans(e.step)
# estimate p,q
p_temp <- sum(obs*e.step[1, ]) / sum(e.step[1,])
q_temp <- sum(obs*e.step[2, ]) / sum(e.step[2,])
r_temp <- sum(obs*e.step[3, ]) / sum(e.step[3,])
list(pi_temp,p_temp,q_temp,r_temp)
}
## EM Algorithm
em.algo <- function(obs, pi_init, inits,maxit=1000,tol=1e-6){
# Initial parameter estimates
flag <- 0
pi_cur <- pi_init; p_cur <- inits[1]; q_cur <- inits[2]; r_cur <- inits[3]
# Iterate between expectation and maximization steps
for(i in 1:maxit){
cur_pi <- pi_cur
cur <- c(p_cur,q_cur, r_cur)
new <- mstep(obs,estep(obs, cur_pi, cur))
pi_new <- new[[1]]; p_new <- new[[2]]; q_new <- new[[3]]; r_new <- new[[4]]
new_step <- c(p_new,q_new, r_new)
new_step_pi <- pi_new
# Stop iteration if the difference between the current and new estimates is less than a tolerance level
#if( all(abs(cur - new_step) < tol) ){ flag <- 1; break}
#if( all(abs(cur_pi - new_step_pi) < tol) ){ flag <- 1; break}
# Otherwise continue iteration
pi_cur <- pi_new; p_cur <- p_new; q_cur <- q_new; r_cur = r_new
if(i%%10==0){
print(pi_cur)
}
}
print(i)
if(!flag) warning("Didn't converge\n")
list(pi_cur, p_cur, q_cur, r_cur)
}
## Generate sample data
n <- 5000
pi_true <- c(1/3, 1/3, 1/3) # prob of using first coin
p_true <-  0.60 # the first coin has P(heads) = 0.60
q_true <-  0.40
r_true <-  0.50# the second coin has P(heads) = 0.50
true <- c(pi_true, p_true, q_true, r_true)
#u <- ifelse(runif(n)<pi_true, rbinom(n,1,p_true),rbinom(n,1,q_true))
u = matrix(nrow = n, ncol = 1)
for(i in 1:n) {
k <- sample(1:3,1,prob=pi_true)
u[i] <- rbinom(1,1,true[k+1])
}
u
## Set parameter estimates
pi_init = c(0.70, 0.10, 0.20); p_init = 0.60; q_init = 0.40; r_init = 0.10
init_vals = c(p_init, q_init, r_init)
## Run EM Algorithm
output <- em.algo(u, pi_init, init_vals, maxit = 100)
## Expectation Step
estep <- function(obs, pi, cur){
pi_estep = matrix(nrow = 3, ncol = length(obs))
tot = ( pi[1]*dbinom(obs,1,cur[1]) + pi[2]*dbinom(obs,1,cur[2]) + pi[3]*dbinom(obs,1,cur[3]) )
for( i in 1:3){
pi_estep[i,] <- (pi[i]*dbinom(obs,1,cur[i])) / tot
}
print(dim(pi_estep))
return(pi_estep)
}
## Run EM Algorithm
output <- em.algo(u, pi_init, init_vals, maxit = 100)
rowprods
?rowprods
installed.packages("rfast")
library(rfast)
library(Rfast)
prod(c(1,2,3))
## Expectation Step
estep <- function(obs, pi, cur){
pi_estep = matrix(nrow = 3, ncol = length(obs))
tot = ( pi[1]*dbinom(obs,1,cur[1]) + pi[2]*dbinom(obs,1,cur[2]) + pi[3]*dbinom(obs,1,cur[3]) )
for( i in 1:3){
pi_estep[i,] <- (pi[i]*dbinom(obs,1,cur[i])) / tot
}
for(i in 1:3){
pi_estep[1,] = prod(pi_estep[1,])
}
print(dim(pi_estep))
return(pi_estep)
}
## Run EM Algorithm
output <- em.algo(u, pi_init, init_vals, maxit = 100)
## Expectation Step
estep <- function(obs, pi, cur){
pi_estep = matrix(nrow = 3, ncol = length(obs))
tot = ( pi[1]*dbinom(obs,1,cur[1]) + pi[2]*dbinom(obs,1,cur[2]) + pi[3]*dbinom(obs,1,cur[3]) )
for( i in 1:3){
pi_estep[i,] <- prod((pi[i]*dbinom(obs,1,cur[i])) / tot)
}
return(pi_estep)
}
## Generate sample data
n <- 5000
pi_true <- c(1/3, 1/3, 1/3) # prob of using first coin
p_true <-  0.60 # the first coin has P(heads) = 0.60
q_true <-  0.40
r_true <-  0.50# the second coin has P(heads) = 0.50
true <- c(pi_true, p_true, q_true, r_true)
#u <- ifelse(runif(n)<pi_true, rbinom(n,1,p_true),rbinom(n,1,q_true))
u = matrix(nrow = n, ncol = 1)
for(i in 1:n) {
k <- sample(1:3,1,prob=pi_true)
u[i] <- rbinom(1,1,true[k+1])
}
## Set parameter estimates
pi_init = c(0.70, 0.10, 0.20); p_init = 0.60; q_init = 0.40; r_init = 0.10
init_vals = c(p_init, q_init, r_init)
## Run EM Algorithm
output <- em.algo(u, pi_init, init_vals, maxit = 100)
## Expectation Step
estep <- function(obs, pi, cur){
pi_estep = matrix(nrow = 3, ncol = length(obs))
tot = ( pi[1]*dbinom(obs,1,cur[1]) + pi[2]*dbinom(obs,1,cur[2]) + pi[3]*dbinom(obs,1,cur[3]) )
for( i in 1:3){
pi_estep[i,] <- (pi[i]*dbinom(obs,1,cur[i])) / tot
}
return(pi_estep)
}
## Maximization Step
mstep <- function(obs,e.step){
# estimate pi
pi_temp <- rowMeans(e.step)
# estimate p,q
p_temp <- sum(obs*e.step[1, ]) / sum(e.step[1,])
q_temp <- sum(obs*e.step[2, ]) / sum(e.step[2,])
r_temp <- sum(obs*e.step[3, ]) / sum(e.step[3,])
list(pi_temp,p_temp,q_temp,r_temp)
}
## EM Algorithm
em.algo <- function(obs, pi_init, inits,maxit=1000,tol=1e-6){
# Initial parameter estimates
flag <- 0
pi_cur <- pi_init; p_cur <- inits[1]; q_cur <- inits[2]; r_cur <- inits[3]
# Iterate between expectation and maximization steps
for(i in 1:maxit){
cur_pi <- pi_cur
cur <- c(p_cur,q_cur, r_cur)
new <- mstep(obs,estep(obs, cur_pi, cur))
pi_new <- new[[1]]; p_new <- new[[2]]; q_new <- new[[3]]; r_new <- new[[4]]
new_step <- c(p_new,q_new, r_new)
new_step_pi <- pi_new
# Stop iteration if the difference between the current and new estimates is less than a tolerance level
#if( all(abs(cur - new_step) < tol) ){ flag <- 1; break}
#if( all(abs(cur_pi - new_step_pi) < tol) ){ flag <- 1; break}
# Otherwise continue iteration
pi_cur <- pi_new; p_cur <- p_new; q_cur <- q_new; r_cur = r_new
if(i%%10==0){
print(pi_cur)
}
}
print(i)
if(!flag) warning("Didn't converge\n")
list(pi_cur, p_cur, q_cur, r_cur)
}
## Generate sample data
n <- 500
pi_true <- c(1/3, 1/3, 1/3) # prob of using first coin
p_true <-  0.60 # the first coin has P(heads) = 0.60
q_true <-  0.40
r_true <-  0.50# the second coin has P(heads) = 0.50
true <- c(pi_true, p_true, q_true, r_true)
#u <- ifelse(runif(n)<pi_true, rbinom(n,1,p_true),rbinom(n,1,q_true))
u = matrix(nrow = n, ncol = 1)
for(i in 1:n) {
k <- sample(1:3,1,prob=pi_true)
u[i] <- rbinom(1,1,true[k+1])
}
## Set parameter estimates
pi_init = c(0.70, 0.10, 0.20); p_init = 0.60; q_init = 0.40; r_init = 0.10
init_vals = c(p_init, q_init, r_init)
## Run EM Algorithm
output <- em.algo(u, pi_init, init_vals, maxit = 100)
a = u[1:10]
a
estep(a, pi_init, c(p_init, q_init, r_init))
setwd("~/Desktop/ML_assignments_LIU/Lab2Block2")
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
library(readxl)
library(ggplot2)
library(reshape2)
library(mgcv)
library(pamr)
install.packages("pamr")
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
library(readxl)
library(ggplot2)
library(reshape2)
library(mgcv)
library(pamr)
library(glmnet)
library(kernlab)
#library(IHW)
library(FSA)
install.packages("FSA")
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
library(readxl)
library(ggplot2)
library(reshape2)
library(mgcv)
library(pamr)
library(glmnet)
library(kernlab)
#library(IHW)
library(FSA)
modelL <-  gam(Mortality~Year+s(Week, k=52, sp=0),data=influenza,family = "gaussian")
# Part 3
preds <- predict(model,data)
# Part 3
preds <- predict(model,influenza)
#A1
#1
influenza = read_xlsx("Influenza.xlsx")
#head(influenza)
ggplot(influenza) + geom_line(aes(Time, Influenza), col = "red")
ggplot(influenza) + geom_line(aes(Time, Mortality), col = "blue")
#ggplot(influenza) + geom_line(aes(Time, Influenza, col="red")) + geom_line(aes(Time, Mortality, col="blue"))
#Part 2
model = gam(Mortality~Year+s(Week, k= length(unique(influenza$Week))), data = influenza, family = gaussian, method = "GCV.Cp")
#plot(model, pages = 1, residuals = T)
summary(model)
# Part 3
preds <- predict(model,influenza)
results <- data.frame(Time=influenza$Time,
Mortality=influenza$Mortality,
Predicted=preds,
Week=influenza$Week,
Year=influenza$Year)
ggplot(results)+
geom_line(aes(x=Time,y=Mortality,color="Original"))+
geom_line(aes(x=Time,y=Predicted,color="predicted"))+
ggtitle("Prediction of Mortality using GAM")
# Part 5
results <- data.frame(Ind=influenza$Time,Original=influenza$Influenza,Residuals=as.data.frame(model$residuals))
colnames(results)[3] <-c("Residuals")
ggplot(results)+
geom_point(aes(x=Ind,y=Original,color="Influenza"))+
geom_line(aes(x=Ind,y=Residuals,color="Residuals"))
# Part 6
allYears <- length(unique(influenza$Year))
allWeeks <- length(unique(influenza$Week))
allInf <- length(unique(influenza$Influenza))
modelFinal <-gam(Mortality~s(Year,k=allYears)
+s(Week,k=allWeeks)
+s(Influenza,k=allInf),data=influenza,
family = "gaussian",method="GCV.Cp")
summary(modelFinal)
preds <- predict(modelFinal,influenza)
results <- data.frame(Ind=influenza$Time,Original=influenza$Mortality,Predicted=preds)
ggplot(results)+
geom_point(aes(x=Ind,y=Original,color="Original"))+
geom_line(aes(x=Ind,y=Predicted,color="Predicted"))
# Part 5
results <- data.frame(Ind=influenza$Time,Original=influenza$Influenza,Residuals=as.data.frame(model$residuals))
colnames(results)
# Part 5
results <- data.frame(Ind=influenza$Time,Original=influenza$Influenza,Residuals=as.data.frame(model$residuals))
colnames(results)[3] <-c("Residuals")
ggplot(results)+
geom_point(aes(x=Ind,y=Original,color="Influenza"))+
geom_line(aes(x=Ind,y=Residuals,color="Residuals"))
# Part 6
allYears <- length(unique(influenza$Year))
allWeeks <- length(unique(influenza$Week))
allInf <- length(unique(influenza$Influenza))
modelFinal <-gam(Mortality~s(Year,k=allYears)
+s(Week,k=allWeeks)
+s(Influenza,k=allInf),data=influenza,
family = "gaussian",method="GCV.Cp")
summary(modelFinal)
preds <- predict(modelFinal,influenza)
results <- data.frame(Ind=influenza$Time,Original=influenza$Mortality,Predicted=preds)
ggplot(results)+
geom_point(aes(x=Ind,y=Original,color="Original"))+
geom_line(aes(x=Ind,y=Predicted,color="Predicted"))
par(mfrow=c(2,2))
plot.gam(modelFinal)
modelL <-  gam(Mortality~Year+s(Week, k=52, sp=0),data=influenza,family = "gaussian")
modelH <-  gam(Mortality~Year+s(Week, k=52, sp=100),data=influenza,family = "gaussian")
predL <- predict(modelL,influenza)
predH <- predict(modelH,influenza)
results <- data.frame(Ind =influenza$Time,Original=influenza$Mortality,PredictedLow=predL,PredictedHigh=predH)
ggplot(results)+
geom_point(aes(x=Ind,y=Original,color="Original"))+
geom_line(aes(x=Ind,y=PredictedLow,color="Low penalty"))+
geom_line(aes(x=Ind,y=PredictedHigh,color="High penalty"))+
xlab("Time")+
ggtitle("Predicted and observed Mortality for low and high penalty factor")
modelL <-  gam(Mortality~Year+s(Week, k=52, sp=0),data=influenza,family = "gaussian")
modelH <-  gam(Mortality~Year+s(Week, k=52, sp=100),data=influenza,family = "gaussian")
predL <- predict(modelL,influenza)
predH <- predict(modelH,influenza)
results <- data.frame(Ind =influenza$Time,Original=influenza$Mortality,PredictedLow=predL,PredictedHigh=predH)
ggplot(results)+
geom_point(aes(x=Ind,y=Original,color="Original"))+
geom_line(aes(x=Ind,y=PredictedLow,color="Low penalty"))+
geom_line(aes(x=Ind,y=PredictedHigh,color="High penalty"))+
xlab("Time")+
ggtitle("Predicted and observed Mortality for low and high penalty factor")
#Part1
set.seed(12345)
data <- read.csv("data.csv",sep = ";",check.names = FALSE ,encoding = "latin1")
data$Conference <- as.factor(data$Conference)
n=dim(data)[1]
id=sample(1:n, floor(n*0.70))
train=data[id,]
test=data[-id,]
cat("Train dimension: ",dim(train),"\nTest dimension: ",dim(test))
#Organize data
rownames(train) <- 1:nrow(train)
trainx <- t(as.matrix(train[,-4703]))
trainy <- as.matrix(train[,4703])
newTrain <- list(x=trainx,y=trainy,geneid=as.character(1:nrow(trainx)),genenames=rownames(trainx))
# fit model
model1 <- pamr.train(newTrain)
## CV model
model.cv <- pamr.cv(model1,newTrain,nfold = 10)
#plot of cv
pamr.plotcv(model.cv)
minThresh <- model.cv$threshold[which.min(model.cv$error)]
#Minimum Error Model
model2 <- pamr.train(newTrain, threshold = minThresh)
# Centroid Plot
pamr.plotcen(model1, newTrain, threshold =minThresh)
#Total features selected
featSelected <- pamr.listgenes(model1, newTrain, threshold = minThresh, genenames=TRUE)
cat("\nTotal Features Selected: ",dim(featSelected)[1])
# Most contributing features (Top 10)
topFeat <- featSelected[1:10,"name"]
cat("\n10 Most contributing features are: ",topFeat)
featSelected <- pamr.listgenes(model1, newTrain, threshold = minThresh, genenames=TRUE)
#Total features selected
cat("\nTotal Features Selected: ",dim(featSelected)[1])
# Most contributing features (Top 10)
topFeat <- featSelected[1:10,"name"]
cat("\n10 Most contributing features are: ",topFeat)
print(featSelected[1:10,2:4])
#Total features selected
cat("\nTotal Features Selected: ",dim(featSelected)[1])
# Most contributing features (Top 10)
topFeat <- featSelected[1:10,"name"]
cat("\n10 Most contributing features are: ",topFeat)
#Total features selected
cat("\nTotal Features Selected: ",dim(featSelected)[1])
# Most contributing features (Top 10)
topFeat <- featSelected[1:10,"name"]
cat("\n10 Most contributing features are: \n",topFeat)
print(featSelected[1:10,2:4])
#Test error
testx <- t(as.matrix(test[,-4703]))
testy <- as.matrix(test[,4703])
preds <- pamr.predict(model1,newx=testx,threshold = minThresh,type="class")
confMat <- table(testy,preds)
print(confMat)
misRate1 <- 1- sum(diag(confMat))/sum(confMat)
cat("\nMisclassification rate on test: ",misRate1)
#Test error
print("Performance on Test set: ")
testx <- t(as.matrix(test[,-4703]))
testy <- as.matrix(test[,4703])
preds <- pamr.predict(model1,newx=testx,threshold = minThresh,type="class")
confMat <- table(testy,preds)
print(confMat)
misRate1 <- 1- sum(diag(confMat))/sum(confMat)
cat("\nMisclassification rate on test: ",misRate1)
#Part 2
set.seed(12345)
trainx <- as.matrix(train[,-4703])
trainy <- as.matrix(train$Conference)
model2 <- glmnet(x=trainx,y=trainy,family = "binomial",alpha = 0.5)
#model.cv <- cv.glmnet(model)
model.cv <- cv.glmnet(x=trainx,y=trainy,family = "binomial",alpha = 0.5)
plot(model.cv)
# test Elastic Net
set.seed(12345)
testx <- as.matrix(test[,-4703])
testy <- as.matrix(test$Conference)
preds <- predict(model2,testx,s = model.cv$lambda.min, type="class")
confMat <- table(testy,preds)
print(confMat)
misRate2 <- 1- sum(diag(confMat))/sum(confMat)
cat("\nMisclassification rate on test Using GLMNET: ",misRate2)
cat("\nNumber of features selected: ",dim(coef(model2))[2])
set.seed(12345)
model3 <- ksvm(Conference~.,data=train,kernel="vanilladot",scaled=FALSE)
print(model3)
# test Elastic Net
set.seed(12345)
testx <- as.matrix(test[,-4703])
testy <- as.matrix(test$Conference)
preds <- predict(model2,testx,s = model.cv$lambda.min, type="class")
confMat <- table(testy,preds)
print(confMat)
misRate2 <- 1- sum(diag(confMat))/sum(confMat)
cat("\nMisclassification rate on test Using GLMNET: ",misRate2)
cat("\nNumber of features selected: ",dim(coef(model2))[2])
preds <- predict(model3,test,type="response")
confMat <- table(Actual=test$Conference,Predicted=preds)
print(confMat)
misRate3 <- 1- sum(diag(confMat))/sum(confMat)
cat("\nMisclassification rate on test Using SVM with Vanilladot Kernel: ",misRate3)
cat("\nNumber of feature selected: ",length(model3@coef[[1]]))
misRates <-c(misRate1,misRate2,misRate3)
models <- c("Nearest Shrunken Centroid","Elastic Net","Support Vector Machine")
featuresSelected <- c(length(topFeat),dim(coef(model2))[2],length(model3@coef[[1]]))
results <- data.frame(Model=models,MisClassificationRates=misRates,FeaturesSelected=featuresSelected)
print(results)
data <- read.csv("data.csv",sep = ";",check.names = FALSE ,encoding = "latin1")
p_value <- c()
for (i in 1:4702){
x <- data[,i]
p_value[i] <- t.test(x ~ Conference, data = data, alternative = "two.sided")$p.value
}
p_value <- c()
for (i in 1:4702){
x <- data[,i]
p_value[i] <- t.test(x ~ Conference, data = data, alternative = "two.sided")$p.value
}
p_value <- as.data.frame(p_value)
p_value$reject_flag <- as.factor(ifelse(p_value$p_value <0.05, "Retain", "Drop"))
p_value$column_index <- row.names(p_value)
keep <- na.omit(ifelse(p_value$reject_flag == "Retain", as.numeric(p_value$column_index), NA))
colnames(data[,keep])
p_value <- c()
for (i in 1:4702){
x <- data[,i]
p_value[i] <- t.test(x ~ Conference, data = data, alternative = "two.sided")$p.value
}
p_value <- as.data.frame(p_value)
p_value$reject_flag <- as.factor(ifelse(p_value$p_value <0.05, "Retain", "Drop"))
p_value$column_index <- row.names(p_value)
keep <- na.omit(ifelse(p_value$reject_flag == "Retain", as.numeric(p_value$column_index), NA))
colnames(data[,keep])
cat("Total Features Selected are : ", length(keep))
